{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpm.distributions import Normal, LogNormal, Laplace, Logistic\n",
    "from torch.nn import Linear, Module, NLLLoss\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "import math\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x):\n",
    "    return 4 * x + 5 + torch.randn((x.shape[0], 1))\n",
    "\n",
    "def function_lap(x):\n",
    "    return 4 * x + 5 + Laplace(learnable=False).sample(x.shape[0])\n",
    "\n",
    "def function_bin(x):\n",
    "    return torch.sigmoid(4*x - 20 + torch.randn((x.shape[0], 1))) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1]) torch.Size([100, 1]) torch.Size([100, 1]) torch.Size([100, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11f944b00>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.tensor(np.linspace(-50, 50., 100)).float().reshape(-1, 1)\n",
    "response = function(data)\n",
    "response_lap = function_lap(data)\n",
    "response_bin = function_bin(data)\n",
    "print(data.size(), response.size(), response_lap.size(), response_bin.size())\n",
    "plt.scatter(data, response_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLM(Module):\n",
    "    \n",
    "    def __init__(self, dist, input_dim=1, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(input_dim, output_dim)\n",
    "        self.dist = dist\n",
    "        \n",
    "    def log_prob(self, x, y):\n",
    "        mu = self.mean(x)\n",
    "        return torch.stack([self.dist(mu[i], learnable=False).log_prob(y[i].reshape(-1, 1)) \n",
    "                            for i in range(x.shape[0])])\n",
    "    \n",
    "    def mean(self, x):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "\n",
    "class NormalGLM(GLM):\n",
    "    \n",
    "    def __init__(self, input_dim=1, output_dim=1):\n",
    "        super().__init__(Normal)\n",
    "        \n",
    "    def mean(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "class LaplaceGLM(GLM):\n",
    "    \n",
    "    def __init__(self, input_dim=1, output_dim=1):\n",
    "        super().__init__(Laplace)\n",
    "        \n",
    "    def mean(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "class Bernoulli(GLM):\n",
    "    \n",
    "    def __init__(self, input_dim=1, output_dim=1):\n",
    "        super().__init__(Logistic)\n",
    "        \n",
    "    def mean(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Bernoulli()\n",
    "optimizer = Adam(m.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1000]\tLoss inf\n",
      "[Epoch 100/1000]\tLoss inf\n",
      "[Epoch 200/1000]\tLoss inf\n",
      "[Epoch 300/1000]\tLoss inf\n",
      "[Epoch 400/1000]\tLoss inf\n",
      "[Epoch 500/1000]\tLoss inf\n",
      "[Epoch 600/1000]\tLoss inf\n",
      "[Epoch 700/1000]\tLoss inf\n",
      "[Epoch 800/1000]\tLoss inf\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = -m.log_prob(data, response_lap).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"[Epoch {epoch}/{epochs}]\\tLoss {loss.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.linear.weight)\n",
    "print(m.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
